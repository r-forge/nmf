<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>purity. NMF 0.10</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="author" content="">

<link href="css/bootstrap.css" rel="stylesheet">
<link href="css/bootstrap-responsive.css" rel="stylesheet">
<link href="css/highlight.css" rel="stylesheet">
<link href="css/staticdocs.css" rel="stylesheet">

<!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="navbar">
  <div class="navbar-inner">
    <div class = "container">
      <a class="brand" href="index.html">NMF 0.10</a>
      <div class="nav">
        <ul class="nav">
        <li><a href="_MAN.html"><i class="icon-home icon-white"></i> Index</a></li>
       </ul>
   	  </div>
    </div>
  </div>
</div>

    <div class="container">
      <header>
        
      </header>
      
      <h1>Purity and Entropy of a Clustering</h1>

<div class="row">
  <div class="span8">
    <h2>Usage</h2>
    <pre>purity(x, y, ...)

entropy(x, y, ...)

<span class="label label-important">S4</span> (NMFfitXn,ANY)
`purity`(x, y, method = "best", ...)

<span class="label label-important">S4</span> (NMFfitXn,ANY)
`entropy`(x, y, method = "best", ...)</pre>
    
    <h2>Arguments</h2>
    <dl>
      <dt>x</dt>
      <dd>an object that can be interpreted as a factor or
  can generate such an object, e.g. via a suitable method
  <code><a href='predict.html'>predict</a></code>, which gives the cluster membership
  for each sample.</dd>
      <dt>y</dt>
      <dd>a factor or an object coerced into a factor that
  gives the true class labels for each sample. It may be
  missing if <code>x</code> is a contingency table.</dd>
      <dt>...</dt>
      <dd>extra arguments to allow extension, and
  usually passed to the next method.</dd>
      <dt>method</dt>
      <dd>a character string that specifies how the
  value is computed. It may be either <code>'best'</code> or
  <code>'mean'</code> to compute the best or mean purity
  respectively.</dd>
    </dl>
    
    <div class="Value">
      <h2>Value</h2>
      
      <p>a single numeric value</p>
  
      <p>the entropy (i.e. a single numeric value)</p>
  
    </div>

    <div class="Description">
      <h2>Description</h2>
      
      <p>The functions <code>purity</code> and <code>entropy</code>
  respectively compute the purity and the entropy of a
  clustering given <em>a priori</em> known classes.</p>
  
      <p>Entropy of a Clustering</p>
  
    </div>

    <div class="Details">
      <h2>Details</h2>
      
      <p>The purity and entropy measure the ability of a
  clustering method, to recover known classes (e.g. one
  knows the true class labels of each sample), that are
  applicable even when the number of cluster is different
  from the number of known classes. <cite>Kim et al.
  (2007)</cite> used these measures to evaluate the performance
  of their alternate least-squares NMF algorithm.</p>
  
      <p>Suppose we are given <code class = 'eq'>l</code> categories, while the
  clustering method generates <code class = 'eq'>k</code> clusters.</p>
  
      <p>The purity of the clustering with respect to the known
  categories is given by: <pre class = 'eq'>Purity = \frac{1}{n}
  \sum_{q=1}^k \max_{1 \leq j \leq l} n_q^j</code> ,</p>
  
      <p>where: <ul>
<li> <code class = 'eq'>n</code> is the total number of
  samples; </li>
<li> <code class = 'eq'>n_q^j</code> is the number of samples in
  cluster <code class = 'eq'>q</code> that belongs to original class <code class = 'eq'>j</code>
  (<code class = 'eq'>1 \leq j \leq l</code>). </li>
</ul></p>
  
      <p>The purity is therefore a real number in <code class = 'eq'>[0,1]</code>. The
  larger the purity, the better the clustering performance.</p>
  
      <p>The entropy of the clustering with respect to the known
  categories is given by: <pre class = 'eq'> - 1/(n log2(l) ) sum_q sum_j n(q,j)
  log2( n(q,j) / n_q )</code>,</p>
  
      <p>where: <ul>
<li> <code class = 'eq'>n</code> is the total number of
  samples; </li>
<li> <code class = 'eq'>n_q</code> is the total number of
  samples in cluster <code class = 'eq'>q</code> (<code class = 'eq'>1 \leq q \leq k</code>); </li>
<li>
  <code class = 'eq'>n(q,j)</code> is the number of samples in cluster
  <code class = 'eq'>q</code> that belongs to original class <code class = 'eq'>j</code> (<code class = 'eq'>1
  \leq j \leq l</code>). </li>
</ul></p>
  
      <p>The smaller the entropy, the better the clustering
  performance.</p>
  
    </div>

    <div class="Methods">
      <h2>Methods</h2>
      
      <p><span class='describe'></p>
  
      <p>entropy<code>signature(x = "table", y =
  "missing")</code>: Computes the purity directly from the
  contingency table <code>x</code>.</p>
  
      <p>This is the workhorse method that is eventually called by
  all other methods.</p>
  
      <p>entropy<code>signature(x = "factor", y = "ANY")</code>:
  Computes the purity on the contingency table of <code>x</code>
  and <code>y</code>, that is coerced into a factor if necessary.</p>
  
      <p>entropy<code>signature(x = "ANY", y = "ANY")</code>:
  Default method that should work for results of clustering
  algorithms, that have a suitable <code>predict</code> method
  that returns the cluster membership vector: the purity is
  computed between <code>x</code> and <code>predict{y}</code></p>
  
      <p>entropy<code>signature(x = "NMFfitXn", y =
  "ANY")</code>: Computes the best or mean entropy across all NMF
  fits stored in <code>x</code>.</p>
  
      <p>purity<code>signature(x = "table", y =
  "missing")</code>: Computes the purity directly from the
  contingency table <code>x</code></p>
  
      <p>purity<code>signature(x = "factor", y = "ANY")</code>:
  Computes the purity on the contingency table of <code>x</code>
  and <code>y</code>, that is coerced into a factor if necessary.</p>
  
      <p>purity<code>signature(x = "ANY", y = "ANY")</code>:
  Default method that should work for results of clustering
  algorithms, that have a suitable <code>predict</code> method
  that returns the cluster membership vector: the purity is
  computed between <code>x</code> and <code>predict{y}</code></p>
  
      <p>purity<code>signature(x = "NMFfitXn", y =
  "ANY")</code>: Computes the best or mean purity across all NMF
  fits stored in <code>x</code>.</p>
  
      <p></span></p>
  
    </div>

    <div class="References">
      <h2>References</h2>
      
      <p>Kim H and Park H (2007). "Sparse non-negative matrix
  factorizations via alternating non-negativity-constrained
  least squares for microarray data analysis."
  _Bioinformatics (Oxford, England)_, *23*(12), pp.
  1495-502. ISSN 1460-2059, <URL:
  http://dx.doi.org/10.1093/bioinformatics/btm134>, <URL:
  http://www.ncbi.nlm.nih.gov/pubmed/17483501>.</p>
  
    </div>
      </div>
  <div class="span4">
    <!-- <ul>
      <li>entropy</li><li>entropy,ANY,ANY-method</li><li>entropy,factor,ANY-method</li><li>entropy-methods</li><li>entropy,NMFfitXn,ANY-method</li><li>entropy,table,missing-method</li><li>purity</li><li>purity,ANY,ANY-method</li><li>purity,factor,ANY-method</li><li>purity-methods</li><li>purity,NMFfitXn,ANY-method</li><li>purity,table,missing-method</li>
    </ul>
    <ul>
      <li>methods</li>
    </ul> -->
      
    <h2>See also</h2>
    
  Other assess: <code><a href='sparseness.html'>sparseness</a></code>

        
  </div>
</div>
      
      <footer>
      <p class="pull-right"><a href="#">Back to top</a></p>
<p>Built by <a href="https://github.com/hadley/staticdocs">staticdocs</a>. Styled with <a href="http://twitter.github.com/bootstrap">bootstrap</a>.</p>
      </footer>
    </div>
  </body>
</html>