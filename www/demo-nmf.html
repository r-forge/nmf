<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>Using the main function nmf(). NMF 0.10.2</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="author" content="">

<link href="css/bootstrap.css" rel="stylesheet">
<link href="css/bootstrap-responsive.css" rel="stylesheet">
<link href="css/highlight.css" rel="stylesheet">
<link href="css/staticdocs.css" rel="stylesheet">

<!-- d3 word cloud -->
<script src="js/d3.v2.min.js"></script>
<script src="js/d3.layout.cloud.js"></script>

<!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="navbar">
  <div class="navbar-inner">
    <div class = "container">
      <a class="brand" href="index.html">NMF 0.10.2</a>
      <div class="nav">
        <ul class="nav">
        <li><a href="_DEMOS.html"><i class="icon-home icon-white"></i> Index</a></li>
       </ul>
   	  </div>
    </div>
  </div>
</div>

    <div class="container">
      <header>
        
      </header>
      
      <h1>Using the main function nmf()</h1><br />

<div class="row"><div class="span8">
  <pre>
  <div class='input'># generate a synthetic dataset with known classes: 50 features, 23 samples (10+5+8)</div><div class='input'>n <- 20; counts <- c(5, 3, 2);
</div><div class='input'>p <- sum(counts)
</div><div class='input'>x <- syntheticNMF(n, counts)
</div><div class='input'>dim(x)
</div>
<div class='output'>[1] 20 10
</div><div class='input'></div><div class='input'># build the true cluster membership</div><div class='input'>groups <- unlist(mapply(rep, seq(counts), counts))
</div><div class='input'></div><div class='input'># run on a data.frame</div><div class='input'>res <- nmf(data.frame(x), 3)
</div><div class='input'></div><div class='input'># missing method: use algorithm suitable for seed</div><div class='input'>res <- nmf(x, 2, seed=rnmf(2, x))
</div><div class='input'>algorithm(res)
</div>
<div class='output'>[1] "brunet"
</div><div class='input'>res <- nmf(x, 2, seed=rnmf(2, x, model='NMFns'))
</div><div class='input'>algorithm(res)
</div>
<div class='output'>[1] "nsNMF"
</div><div class='input'></div><div class='input'># compare some NMF algorithms (tracking the approximation error)</div><div class='input'>res <- nmf(x, 2, list('brunet', 'lee', 'nsNMF'), .options='t')
</div>
<div class='output'>Compute NMF method 'brunet' [1/3] ... OK
Compute NMF method 'lee' [2/3] ... OK
Compute NMF method 'nsNMF' [3/3] ... OK
</div><div class='input'>res
</div>
<div class='output'><Object of class: NMFList >
Length: 3 
Method(s): brunet, lee, nsNMF 
Total timing:
   user  system elapsed 
  1.276   0.004   1.283 
</div><div class='input'>summary(res, class=groups)
</div>
<div class='output'>       method   seed rng    metric rank sparseness.basis sparseness.coef purity   entropy residuals niter   cpu cpu.all nrun
brunet brunet random   1        KL    2        0.3241285       0.5267872    0.7 0.5523719  50.33594   420 0.168   0.168    1
lee       lee random   1 euclidean    2        0.3156294       0.4996006    0.6 0.6126016  27.20371   450 0.252   0.252    1
nsNMF   nsNMF random   1        KL    2        0.3970087       0.7120646    0.7 0.5523719  55.44895   420 0.316   0.316    1
</div><div class='input'></div><div class='input'># plot the track of the residual errors</div><div class='input'>plot(res)
</div><p><img src='nmf-demo1.png' alt='' width='400' height='400' /></p><div class='input'></div><div class='input'># specify algorithm by its name</div><div class='input'>res <- nmf(x, 3, 'nsNMF', seed=123) # nonsmooth NMF
</div><div class='input'># names are partially matched so this also works</div><div class='input'>identical(res, nmf(x, 3, 'ns', seed=123))
</div>
<div class='output'>[1] FALSE
</div><div class='input'></div><div class='input'>res <- nmf(x, 3, 'offset') # NMF with offset
</div><div class='input'></div><div class='input'># run a custom algorithm defined as a standard function</div><div class='input'>myfun <- function(x, start, alpha){
# update starting point
# ...
basis(start) <- 3 * basis(start)
# return updated point
start
}
</div><div class='input'></div><div class='input'>res <- nmf(x, 2, myfun, alpha=3)
</div><div class='input'>algorithm(res)
</div>
<div class='output'>[1] "nmf_692a6c74d847"
</div><div class='input'># error: alpha missing</div><div class='input'>try( nmf(x, 2, myfun) )
</div>
<div class='output'><Object of class: NMFfit>
 # Model:
  <Object of class:NMFstd>
  features: 20 
  basis/rank: 2 
  samples: 10 
 # Details:
  algorithm:  nmf_692a400970f3 
  seed:  random 
  RNG: 403L, 258L, ..., -480077127L [7705ea1d978a86d69d8ea85cfbb9770f]
  distance metric:  'euclidean' 
  residuals:  28378.06 
  Timing:
     user  system elapsed 
    0.004   0.000   0.003 
</div><div class='input'></div><div class='input'># possibly the algorithm fits a non-standard NMF model, e.g. NMFns model</div><div class='input'>res <- nmf(x, 2, myfun, alpha=3, model='NMFns')
</div><div class='input'>modelname(res)
</div>
<div class='output'>[1] "NMFns"
</div><div class='input'></div><div class='input'># assume a known NMF model compatible with the matrix `x`</div><div class='input'>y <- rnmf(3, x)
</div><div class='input'># fits an NMF model (with default method) on some data using y as a starting point</div><div class='input'>res <- nmf(x, y)
</div><div class='input'># the fit can be reproduced using the same starting point</div><div class='input'>nmf.equal(nmf(x, y), res)
</div>
<div class='output'>[1] TRUE
</div><div class='input'></div><div class='input'># missing method: use default algorithm</div><div class='input'>res <- nmf(x, 3)
</div><div class='input'></div><div class='input'># Fit a 3-rank model providing an initial value for the basis matrix</div><div class='input'>nmf(x, rmatrix(nrow(x), 3), 'snmf/r')
</div>
<div class='output'><Object of class: NMFfit>
 # Model:
  <Object of class:NMFstd>
  features: 20 
  basis/rank: 3 
  samples: 10 
 # Details:
  algorithm:  snmf/r 
  seed:  none 
  RNG: 403L, 618L, ..., -480077127L [80c64550a3ad7363d023dfc48e0bfbf3]
  distance metric:  <function> 
  residuals:  23.90494 
  Iterations: 65 
  Timing:
     user  system elapsed 
    0.264   0.000   0.274 
</div><div class='input'></div><div class='input'># Fit a 3-rank model providing an initial value for the mixture coefficient matrix</div><div class='input'>nmf(x, rmatrix(3, ncol(x)), 'snmf/l')
</div>
<div class='output'><Object of class: NMFfit>
 # Model:
  <Object of class:NMFstd>
  features: 20 
  basis/rank: 3 
  samples: 10 
 # Details:
  algorithm:  snmf/l 
  seed:  none 
  RNG: 403L, 39L, ..., 1885291402L [b9e91cc4320d0c6a85afe151b7b98e6a]
  distance metric:  <function> 
  residuals:  24.26068 
  Iterations: 60 
  Timing:
     user  system elapsed 
    0.220   0.000   0.217 
</div><div class='input'></div><div class='input'># default fit</div><div class='input'>res <- nmf(x, 2)
</div><div class='input'>summary(res, class=groups)
</div>
<div class='output'>            rank sparseness.basis  sparseness.coef           purity          entropy        residuals            niter              cpu          cpu.all             nrun 
       2.0000000        0.3241329        0.5179643        0.7000000        0.5523719       50.3359557      430.0000000        0.1600000        0.1600000        1.0000000 
</div><div class='input'></div><div class='input'># run default algorithm multiple times (only keep the best fit)</div><div class='input'>res <- nmf(x, 3, nrun=10)
</div><div class='input'>res
</div>
<div class='output'><Object of class: NMFfitX1 >
  Method: brunet 
  Runs:  10 
  RNG:
   407L, -1127056460L, 1619604261L, 2023478690L, 1413827771L, 1293873344L, 1153468865L 
  Total timing:
   user  system elapsed 
  2.552   0.204   4.695 
</div><div class='input'>summary(res, class=groups)
</div>
<div class='output'>            rank sparseness.basis  sparseness.coef           purity          entropy        residuals            niter              cpu          cpu.all             nrun 
       3.0000000        0.4658515        0.6330216        0.9000000        0.2047438       38.1780145      440.0000000        0.1840000        2.5520000       10.0000000 
      cophenetic       dispersion 
       0.8828346        0.5592000 
</div><div class='input'></div><div class='input'># run default algorithm multiple times keeping all the fits</div><div class='input'>res <- nmf(x, 3, nrun=10, .options='k')
</div><div class='input'>res
</div>
<div class='output'><Object of class: NMFfitXn >
  Method: brunet 
  Runs:  10 
  RNG:
   407L, 997742575L, 331648356L, 1559710997L, 1309133522L, -1403251669L, -957524624L 
  Total timing:
   user  system elapsed 
  4.124   0.348   3.122 
  Sequential timing:
   user  system elapsed 
  1.844   0.024   2.213 
</div><div class='input'>summary(res, class=groups)
</div>
<div class='output'>            rank sparseness.basis  sparseness.coef           purity          entropy        residuals            niter              cpu          cpu.all             nrun 
       3.0000000        0.4456147        0.6920101        0.9000000        0.2047438       38.1167787      440.0000000        0.1760000        4.1240000       10.0000000 
      cophenetic       dispersion 
       0.9184652        0.5160000 
</div><div class='input'></div><div class='input'>## Note: one could have equivalently done</div><div class='input'># res <- nmf(V, 3, nrun=10, .options=list(keep.all=TRUE))</div><div class='input'></div><div class='input'># use a method that fit different model</div><div class='input'>res <- nmf(x, 2, 'nsNMF')
</div><div class='input'>fit(res)
</div>
<div class='output'><Object of class:NMFns>
features: 20 
basis/rank: 2 
samples: 10 
theta: 0.5 
</div><div class='input'></div><div class='input'># pass parameter theta to the model via `...`</div><div class='input'>res <- nmf(x, 2, 'nsNMF', theta=0.2)
</div><div class='input'>fit(res)
</div>
<div class='output'><Object of class:NMFns>
features: 20 
basis/rank: 2 
samples: 10 
theta: 0.2 
</div><div class='input'></div><div class='input'>## handling arguments in `...` and model parameters</div><div class='input'>myfun <- function(x, start, theta=100){ cat("theta in myfun=", theta, "\n\n"); start }
</div><div class='input'># no conflict: default theta</div><div class='input'>fit( nmf(x, 2, myfun) )
</div>
<div class='output'>theta in myfun= 100 

</div>
<div class='output'><Object of class:NMFstd>
features: 20 
basis/rank: 2 
samples: 10 
</div><div class='input'># no conlfict: theta is passed to the algorithm</div><div class='input'>fit( nmf(x, 2, myfun, theta=1) )
</div>
<div class='output'>theta in myfun= 1 

</div>
<div class='output'><Object of class:NMFstd>
features: 20 
basis/rank: 2 
samples: 10 
</div><div class='input'># conflict: theta is used as model parameter</div><div class='input'>fit( nmf(x, 2, myfun, model='NMFns', theta=0.1) )
</div>
<div class='output'>theta in myfun= 100 

</div>
<div class='output'><Object of class:NMFns>
features: 20 
basis/rank: 2 
samples: 10 
theta: 0.1 
</div><div class='input'># conflict solved: can pass different theta to model and algorithm</div><div class='input'>fit( nmf(x, 2, myfun, model=list('NMFns', theta=0.1), theta=5) )
</div>
<div class='output'>theta in myfun= 5 

</div>
<div class='output'><Object of class:NMFns>
features: 20 
basis/rank: 2 
samples: 10 
theta: 0.1 
</div><div class='input'></div><div class='input'>## USING SEEDING METHODS</div><div class='input'></div><div class='input'># run default algorithm with the Non-negative Double SVD seeding method ('nndsvd')</div><div class='input'>res <- nmf(x, 3, seed='nndsvd')
</div><div class='input'></div><div class='input'>## Note: partial match also works</div><div class='input'>identical(res, nmf(x, 3, seed='nn'))
</div>
<div class='output'>[1] FALSE
</div><div class='input'></div><div class='input'># run nsNMF algorithm, fixing the seed of the random number generator</div><div class='input'>res <- nmf(x, 3, 'nsNMF', seed=123456)
</div><div class='input'>nmf.equal(nmf(x, 3, 'nsNMF', seed=123456), res)
</div>
<div class='output'>[1] TRUE
</div><div class='input'></div><div class='input'># run default algorithm specifying the starting point following the NMF standard model</div><div class='input'>start.std <- nmfModel(W=matrix(0.5, n, 3), H=matrix(0.2, 3, p))
</div><div class='input'>nmf(x, start.std)
</div>
<div class='output'><Object of class: NMFfit>
 # Model:
  <Object of class:NMFstd>
  features: 20 
  basis/rank: 3 
  samples: 10 
 # Details:
  algorithm:  brunet 
  seed:  none 
  RNG: 403L, 487L, ..., 1885291402L [3d791d8bf423c5110ca8cb5b6a532fc5]
  distance metric:  'KL' 
  residuals:  50.33594 
  Iterations: 490 
  Timing:
     user  system elapsed 
    0.176   0.000   0.180 
</div><div class='input'></div><div class='input'># to run nsNMF algorithm with an explicit starting point, this one</div><div class='input'># needs to follow the 'NMFns' model:</div><div class='input'>start.ns <- nmfModel(model='NMFns', W=matrix(0.5, n, 3), H=matrix(0.2, 3, p))
</div><div class='input'>nmf(x, start.ns)
</div>
<div class='output'><Object of class: NMFfit>
 # Model:
  <Object of class:NMFns>
  features: 20 
  basis/rank: 3 
  samples: 10 
  theta: 0.5 
 # Details:
  algorithm:  nsNMF 
  seed:  none 
  RNG: 403L, 487L, ..., 1885291402L [3d791d8bf423c5110ca8cb5b6a532fc5]
  distance metric:  'KL' 
  residuals:  55.44237 
  Iterations: 570 
  Timing:
     user  system elapsed 
    0.416   0.008   0.423 
</div><div class='input'># Note: the method name does not need to be specified as it is infered from the</div><div class='input'># when there is only one algorithm defined for the model.</div><div class='input'></div><div class='input'># if the model is not appropriate (as defined by the algorihtm) an error is thrown</div><div class='input'># [cf. the standard model doesn't include a smoothing parameter used in nsNMF]</div><div class='input'>try( nmf(x, start.std, method='nsNMF') )
</div><div class='input'></div><div class='input'>## Callback functions</div><div class='input'># Pass a callback function to only save summary measure of each run</div><div class='input'>res <- nmf(x, 3, nrun=3, .callback=summary)
</div><div class='input'># the callback results are simplified into a matrix</div><div class='input'>res$.callback
</div>
<div class='output'>                        [,1]        [,2]        [,3]
rank               3.0000000   3.0000000   3.0000000
sparseness.basis   0.3914820   0.4984664   0.5090647
sparseness.coef    0.6928829   0.5622632   0.6080111
residuals         39.6233484  39.5786682  39.3080091
niter            430.0000000 440.0000000 470.0000000
cpu                0.1640000   0.1840000   0.1840000
cpu.all            0.1640000   0.1840000   0.1840000
nrun               1.0000000   1.0000000   1.0000000
</div><div class='input'>res <- nmf(x, 3, nrun=3, .callback=summary, .opt='-S')
</div><div class='input'># the callback results are simplified into a matrix</div><div class='input'>res$.callback
</div>
<div class='output'>[[1]]
            rank sparseness.basis  sparseness.coef        residuals            niter              cpu          cpu.all             nrun 
       3.0000000        0.4625371        0.6262392       39.6422584      430.0000000        0.1680000        0.1680000        1.0000000 

[[2]]
            rank sparseness.basis  sparseness.coef        residuals            niter              cpu          cpu.all             nrun 
       3.0000000        0.3732753        0.7566065       40.1436203      440.0000000        0.1840000        0.1840000        1.0000000 

[[3]]
            rank sparseness.basis  sparseness.coef        residuals            niter              cpu          cpu.all             nrun 
       3.0000000        0.3549423        0.8076656       40.1031384      490.0000000        0.1800000        0.1800000        1.0000000 

</div><div class='input'></div><div class='input'># Pass a custom callback function</div><div class='input'>cb <- function(obj, i){ if( i %% 2 ) sparseness(obj) >= 0.5 }
</div><div class='input'>res <- nmf(x, 3, nrun=3, .callback=cb)
</div><div class='input'>res$.callback
</div>
<div class='output'>[[1]]
basis  coef 
FALSE  TRUE 

[[2]]
NULL

[[3]]
basis  coef 
FALSE  TRUE 

</div><div class='input'></div><div class='input'># Passs a callback function which throws an error</div><div class='input'>cb <- function(){ i<-0; function(object){ i <<- i+1; if( i == 1 ) stop('SOME BIG ERROR'); summary(object) }}
</div><div class='input'>res <- nmf(x, 3, nrun=3, .callback=cb())
</div>
<strong class='warning'>Warning message:
NMF::nmf - All NMF fits were successful but 2/3 callback call(s) threw an error.
# Callback error(s) thrown:
  - run #1: SOME BIG ERROR</strong><div class='input'></div><div class='input'>## PARALLEL COMPUTATIONS</div><div class='input'># try using 3 cores, but use sequential if not possible</div><div class='input'>res <- nmf(x, 3, nrun=3, .options='p3')
</div><div class='input'></div><div class='input'># force using 3 cores, error if not possible</div><div class='input'>res <- nmf(x, 3, nrun=3, .options='P3')
</div>
<strong class='error'>Error: Parallel computation aborted: only 2 core(s) available [requested 3 core(s)]</strong><div class='input'></div><div class='input'># use externally defined cluster</div><div class='input'>library(parallel)
</div><div class='input'>cl <- makeCluster(6)
</div><div class='input'>res <- nmf(x, 3, nrun=3, .pbackend=cl)
</div><div class='input'></div><div class='input'># use externally registered backend</div><div class='input'>registerDoParallel(cl)
</div><div class='input'>res <- nmf(x, 3, nrun=3, .pbackend=NULL)</div>
  </pre>
</div></div>
      
      <footer>
      <p class="pull-right"><a href="#">Back to top</a></p>
<p>Built by <a href="https://github.com/hadley/staticdocs">staticdocs</a>. Styled with <a href="http://twitter.github.com/bootstrap">bootstrap</a>.</p>
      </footer>
    </div>
  </body>
</html>